"""
Ù…Ù†ØµØ© Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ ÙˆØªØ´ÙƒÙŠÙ„ Ø£ÙˆØ§Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
Arabic Spelling Corrector and I'rab Marker
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import re
from typing import List, Dict

app = FastAPI(
    title="Ù…ØµØ­Ø­ ÙˆÙ…Ø´ÙƒÙ‘Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    description="Ù…Ù†ØµØ© Ù„Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ ÙˆØªØ´ÙƒÙŠÙ„ Ø£ÙˆØ§Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    version="1.0.0"
)

# Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø·Ù„Ø¨Ø§Øª CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class TextInput(BaseModel):
    text: str


class Correction(BaseModel):
    original: str
    corrected: str
    position: int


class TextOutput(BaseModel):
    original: str
    corrected: str
    marked: str
    corrections: List[Correction]
    stats: Dict[str, int]


class SpellChecker:
    """Ù…ØµØ­Ø­ Ø¥Ù…Ù„Ø§Ø¦ÙŠ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
    
    def __init__(self):
        # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        self.corrections = {
            # Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù‡Ù…Ø²Ø©
            'Ø§Ù„Ù‰': 'Ø¥Ù„Ù‰',
            'Ø¹Ù„Ù‰': 'Ø¹Ù„Ù‰',
            'Ø§Ù„Ù„Ø©': 'Ø§Ù„Ù„Ù‡',
            'Ø§ÙƒØ«Ø±': 'Ø£ÙƒØ«Ø±',
            'Ø§ÙØ¶Ù„': 'Ø£ÙØ¶Ù„',
            'Ø§Ø­Ø¯': 'Ø£Ø­Ø¯',
            'Ø§Ø­Ø³Ù†': 'Ø£Ø­Ø³Ù†',
            'Ø§Ø¬Ù…Ù„': 'Ø£Ø¬Ù…Ù„',
            'Ø§ÙƒØ¨Ø±': 'Ø£ÙƒØ¨Ø±',
            'Ø§ØµØºØ±': 'Ø£ØµØºØ±',
            
            # Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø©
            'Ø§Ù„Ù…Ø¯Ø±Ø³Ù‡': 'Ø§Ù„Ù…Ø¯Ø±Ø³Ø©',
            'Ø§Ù„Ø¬Ø§Ù…Ø¹Ù‡': 'Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©',
            'Ø§Ù„Ù…ÙƒØªØ¨Ù‡': 'Ø§Ù„Ù…ÙƒØªØ¨Ø©',
            'Ø§Ù„Ø­ÙŠØ§Ù‡': 'Ø§Ù„Ø­ÙŠØ§Ø©',
            'Ø§Ù„Ø³Ø¹Ø§Ø¯Ù‡': 'Ø§Ù„Ø³Ø¹Ø§Ø¯Ø©',
            'Ø§Ù„ØµØ­Ù‡': 'Ø§Ù„ØµØ­Ø©',
            'Ø§Ù„ØºØ±ÙÙ‡': 'Ø§Ù„ØºØ±ÙØ©',
            'Ø§Ù„Ø´Ø±ÙƒÙ‡': 'Ø§Ù„Ø´Ø±ÙƒØ©',
            
            # Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø£Ù„Ù Ø§Ù„Ù…Ù‚ØµÙˆØ±Ø© ÙˆØ§Ù„Ù„ÙŠÙ†Ø©
            'Ø¹Ù„ÙŠ': 'Ø¹Ù„Ù‰',
            'Ø§Ù„ÙŠ': 'Ø¥Ù„Ù‰',
            'Ù…ØªÙ‰': 'Ù…ØªÙ‰',
            
            # Ø£Ø®Ø·Ø§Ø¡ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
            'Ù‡Ø§Ø°Ø§': 'Ù‡Ø°Ø§',
            'Ù‡Ø§Ø°Ù‡': 'Ù‡Ø°Ù‡',
            'Ù‡Ø§Ø¤Ù„Ø§Ø¡': 'Ù‡Ø¤Ù„Ø§Ø¡',
            'Ø°Ø§Ù„Ùƒ': 'Ø°Ù„Ùƒ',
            'ØªØ§Ù„Ùƒ': 'ØªÙ„Ùƒ',
            
            # Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø£ÙØ¹Ø§Ù„
            'Ø°Ù‡Ø¨Ùˆ': 'Ø°Ù‡Ø¨ÙˆØ§',
            'Ø¯Ø±Ø³Ùˆ': 'Ø¯Ø±Ø³ÙˆØ§',
            'ÙƒØªØ¨Ùˆ': 'ÙƒØªØ¨ÙˆØ§',
            'Ù‚Ø±Ø¡Ùˆ': 'Ù‚Ø±Ø£ÙˆØ§',
            'Ø§ÙƒÙ„Ùˆ': 'Ø£ÙƒÙ„ÙˆØ§',
            'Ø´Ø±Ø¨Ùˆ': 'Ø´Ø±Ø¨ÙˆØ§',
            
            # Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø© Ø£Ø®Ø±Ù‰
            'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'Ø§Ù„Ø±ÙŠØ§Ø¶Ù‡': 'Ø§Ù„Ø±ÙŠØ§Ø¶Ø©',
            'ÙƒØªØ§Ø¨Ù‡': 'ÙƒØªØ§Ø¨Ø©',
            'Ù‚Ø±Ø¡Ù‡': 'Ù‚Ø±Ø§Ø¡Ø©',
            'Ù‚Ø±Ø¡': 'Ù‚Ø±Ø£',
            'Ù…Ø¨Ø§Ø±Ùƒ': 'Ù…Ø¨Ø§Ø±Ùƒ',
        }
    
    def correct_text(self, text: str) -> tuple[str, list]:
        """ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Øµ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­ Ù…Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª"""
        corrections_list = []
        words = text.split()
        corrected_words = []
        
        for i, word in enumerate(words):
            # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
            clean_word = re.sub(r'[^\w\s]', '', word)
            
            if clean_word in self.corrections:
                corrected = self.corrections[clean_word]
                # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
                for char in word:
                    if not char.isalnum() and char not in 'Ù‹ÙŒÙÙÙÙÙ‘Ù’':
                        corrected += char
                
                corrections_list.append({
                    'original': word,
                    'corrected': corrected,
                    'position': i
                })
                corrected_words.append(corrected)
            else:
                corrected_words.append(word)
        
        return ' '.join(corrected_words), corrections_list


class IrabMarker:
    """Ù…Ø´ÙƒÙ‘Ù„ Ø£ÙˆØ§Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨"""
    
    def __init__(self):
        # Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±
        self.prepositions = ['ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ø¨', 'Ù„', 'Ùƒ']
        
        # Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ù…ØªØ¹Ø¯ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        self.transitive_verbs = ['Ø¯Ø±Ø³', 'ÙƒØªØ¨', 'Ù‚Ø±Ø£', 'Ø£ÙƒÙ„', 'Ø´Ø±Ø¨', 'ÙØ¹Ù„', 'ØµÙ†Ø¹']
    
    def mark_text(self, text: str) -> str:
        """Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ù„Ø£ÙˆØ§Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
        sentences = re.split(r'[.!ØŸ]', text)
        marked_sentences = []
        
        for sentence in sentences:
            if sentence.strip():
                marked = self._mark_sentence(sentence.strip())
                marked_sentences.append(marked)
        
        return '. '.join(marked_sentences)
    
    def _mark_sentence(self, sentence: str) -> str:
        """ØªØ´ÙƒÙŠÙ„ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"""
        words = sentence.split()
        marked_words = []
        
        for i, word in enumerate(words):
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ØªØ´ÙƒÙŠÙ„ Ù…ÙˆØ¬ÙˆØ¯
            clean_word = re.sub(r'[Ù‹ÙŒÙÙÙÙÙ‘Ù’]', '', word)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            if i == 0:
                # Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø© - Ù…Ø¨ØªØ¯Ø£ Ø£Ùˆ ÙØ§Ø¹Ù„ (Ù…Ø±ÙÙˆØ¹)
                marked_word = clean_word + 'Ù'
            elif i > 0 and words[i-1] in self.prepositions:
                # Ø¨Ø¹Ø¯ Ø­Ø±Ù Ø¬Ø± (Ù…Ø¬Ø±ÙˆØ±)
                marked_word = clean_word + 'Ù'
            elif i > 0 and any(verb in words[i-1] for verb in self.transitive_verbs):
                # Ø¨Ø¹Ø¯ ÙØ¹Ù„ Ù…ØªØ¹Ø¯ÙŠ (Ù…Ù†ØµÙˆØ¨)
                marked_word = clean_word + 'Ù'
            elif clean_word.startswith('Ø§Ù„'):
                # Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ø§Ø¯Ø© Ù…Ø±ÙÙˆØ¹Ø© Ø£Ùˆ Ù…Ø¬Ø±ÙˆØ±Ø©
                if i > 0 and words[i-1] in self.prepositions:
                    marked_word = clean_word + 'Ù'
                else:
                    marked_word = clean_word + 'Ù'
            else:
                # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹: Ù…Ù†ØµÙˆØ¨
                marked_word = clean_word + 'Ù'
            
            marked_words.append(marked_word)
        
        return ' '.join(marked_words)


# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø® Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
spell_checker = SpellChecker()
irab_marker = IrabMarker()


@app.get("/")
async def root():
    """Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    return {
        "message": "ğŸ‰ Welcome to Arabic Text Corrector API",
        "service": "Ù…ØµØ­Ø­ ÙˆÙ…Ø´ÙƒÙ‘Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "version": "1.0.0",
        "endpoints": {
            "health": "/api/health",
            "process": "/api/process (POST)",
            "docs": "/docs"
        },
        "example": {
            "method": "POST",
            "url": "/api/process",
            "body": {"text": "Ø§Ù„Ø·Ø§Ù„Ø¨ Ø°Ù‡Ø¨ Ø§Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø±Ø³Ù‡"}
        }
    }


@app.get("/api/health")
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø©"""
    return {
        "status": "healthy",
        "service": "Arabic Text Processor",
        "version": "1.0.0"
    }


@app.post("/api/process", response_model=TextOutput)
async def process_text(input_data: TextInput):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ: ØªØµØ­ÙŠØ­ Ø¥Ù…Ù„Ø§Ø¦ÙŠ + ØªØ´ÙƒÙŠÙ„ Ø£ÙˆØ§Ø®Ø±"""
    try:
        original_text = input_data.text
        
        # 1. Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ
        corrected_text, corrections = spell_checker.correct_text(original_text)
        
        # 2. ØªØ´ÙƒÙŠÙ„ Ø£ÙˆØ§Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        marked_text = irab_marker.mark_text(corrected_text)
        
        # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        sentences = re.split(r'[.!ØŸ]', original_text)
        sentences = [s for s in sentences if s.strip()]
        words = original_text.split()
        
        result = {
            'original': original_text,
            'corrected': corrected_text,
            'marked': marked_text,
            'corrections': corrections,
            'stats': {
                'corrections_count': len(corrections),
                'words_count': len(words),
                'sentences_count': len(sentences),
                'words_marked': len(marked_text.split())
            }
        }
        
        return TextOutput(
            original=result['original'],
            corrected=result['corrected'],
            marked=result['marked'],
            corrections=[
                Correction(
                    original=c['original'],
                    corrected=c['corrected'],
                    position=c['position']
                ) for c in result['corrections']
            ],
            stats=result['stats']
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    import os
    
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")
